# ElevenLabs Conversational AI Migration Plan

## Status: ‚úÖ IMPLEMENTATION COMPLETE - READY TO TEST
**Created:** 2024-11-24
**Implemented:** 2024-11-24
**Agent ID:** `agent_7601k2d8gd4rehpt5xsd81q8bj1m`
**API Key:** Added to `.env`
**Preview Test:** ‚úÖ PERFECT - No interruptions!
**Code Status:** ‚úÖ Syntax validated, ready for local testing

---

## Why We're Migrating

### Current System Issues:
- ‚ùå OpenAI Realtime API VAD interrupts users mid-sentence
- ‚ùå Simple VAD treats "hmm", "okay" as interruptions
- ‚ùå Lacks contextual awareness for turn-taking
- ‚ùå Required multiple prompt fixes that didn't work

### ElevenLabs Solution:
- ‚úÖ Proprietary turn-taking model with prosodic analysis
- ‚úÖ Contextual awareness (won't interrupt mid-sentence)
- ‚úÖ Perfect test results in preview
- ‚úÖ LLM flexibility (can switch between GPT-4o, Claude, Gemini)
- ‚úÖ 5,000+ voices vs OpenAI's 10
- ‚úÖ Enterprise-ready (HIPAA, SOC 2, GDPR)

---

## Architecture Change

### Before (Current):
```
Twilio ‚Üí FastAPI Server ‚Üí OpenAI Realtime API ‚Üí Manual ElevenLabs TTS ‚Üí Twilio
         |
         ‚îú‚îÄ Manual response.create triggers
         ‚îú‚îÄ Complex VAD configuration
         ‚îî‚îÄ Text-only mode bridging
```

### After (New):
```
Twilio ‚Üí FastAPI Server ‚Üí ElevenLabs Conversational AI ‚Üí Twilio
         |
         ‚îú‚îÄ Automatic turn-taking (no manual triggers!)
         ‚îú‚îÄ Simpler event handling
         ‚îî‚îÄ Direct audio passthrough
```

**Complexity Reduction:** ~40% less code, simpler flow, fewer bugs

---

## What Stays Exactly the Same

‚úÖ **Database Functions** - All Supabase queries unchanged
‚úÖ **Calendar Booking** - All Google Calendar code unchanged
‚úÖ **Email Functions** - All Resend/SMTP code unchanged
‚úÖ **Twilio Integration** - TwiML and webhooks unchanged
‚úÖ **Business Logic** - Customer info extraction, lead tracking
‚úÖ **Session Management** - SESSIONS dict structure
‚úÖ **FastAPI Endpoints** - `/inbound`, `/outbound`, `/health`
‚úÖ **Scheduler** - Daily digest emails unchanged

**Total Preservation:** ~80% of codebase

---

## What Changes

### 1. WebSocket Connection (Main Change)

**Remove:**
```python
# OpenAI Realtime API connection
openai_ws = await websockets.connect(
    "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
    extra_headers={"Authorization": f"Bearer {OPENAI_API_KEY}"}
)
```

**Add:**
```python
# ElevenLabs Conversational AI connection
elevenlabs_ws = await websockets.connect(
    f"wss://api.elevenlabs.io/v1/convai/conversation?agent_id={ELEVENLABS_AGENT_ID}",
    extra_headers={"xi-api-key": ELEVENLABS_CONVERSATIONAL_API_KEY}
)
```

### 2. Event Handling (Simplified)

**Remove:**
- `session.update` configuration
- `session.created` handling
- `response.create` manual triggers
- `response.done` event parsing
- `response.text.delta` handling
- `input_audio_transcription.completed` logic
- Complex VAD settings

**Add:**
- `audio` event handling (simpler!)
- `transcript` event logging
- `conversation_initiation_metadata` handling
- Automatic turn-taking (no triggers needed!)

### 3. Configuration

**Remove from .env / code:**
- `OPENAI_API_KEY` (but keep for future use)
- `MODEL` variable
- VAD `threshold`, `silence_duration_ms` settings
- `VOICE` parameter
- `TEMPERATURE` (moved to agent config)

**Add to .env:**
```bash
ELEVENLABS_AGENT_ID=agent_7601k2d8gd4rehpt5xsd81q8bj1m
ELEVENLABS_CONVERSATIONAL_API_KEY=b03d0247...
USE_ELEVENLABS_CONVERSATIONAL_AI=true
```

---

## Implementation Steps

### Step 1: Research API Details ‚úÖ COMPLETE
- ‚úÖ Found exact WebSocket message formats (from GitHub examples)
- ‚úÖ Understand event types (client ‚Üí server, server ‚Üí client)
- ‚úÖ Verified audio format requirements (Œº-law base64 - same as Twilio!)
- ‚úÖ Documented all event formats
- ‚ö†Ô∏è Function calling / tools NOT supported (handle in custom logic)

**Resources Used:**
- GitHub example: https://github.com/louisjoecodes/elevenlabs-twilio-i-o
- Cloned and analyzed source code
- Verified all message formats

### Step 2: Create Feature Flag ‚úÖ COMPLETE
```python
# Added to bolt_realtime.py line 158
USE_ELEVENLABS_CONVERSATIONAL_AI = os.getenv("USE_ELEVENLABS_CONVERSATIONAL_AI", "false").lower() == "true"
```

**Implementation:**
- Routing logic in `/media-stream` endpoint (line 2062)
- Routes to `handle_media_stream_elevenlabs()` when enabled
- Falls back to OpenAI Realtime API when disabled
- Instant rollback: just set env var to `false`

### Step 3: Implement WebSocket Handler ‚úÖ COMPLETE
```python
# Added to bolt_realtime.py line 1868-2053
async def get_elevenlabs_signed_url():
    """Get authenticated signed URL from ElevenLabs API"""

async def handle_media_stream_elevenlabs(websocket: WebSocket, call_sid: str):
    """Complete Twilio <-> ElevenLabs bridge implementation"""
```

**Implemented Features:**
- ‚úÖ Authentication via signed URL
- ‚úÖ Bidirectional audio streaming (Twilio ‚Üî ElevenLabs)
- ‚úÖ Event handling: audio, transcripts, interruptions, pings
- ‚úÖ Automatic interruption detection (clears Twilio buffer)
- ‚úÖ Ping/pong keepalive
- ‚úÖ Comprehensive error handling & logging
- ‚úÖ Graceful WebSocket cleanup

**Key Functions:**
- `receive_from_twilio()` - Forwards audio chunks to ElevenLabs
- `receive_from_elevenlabs()` - Processes all server events
- Both run concurrently via `asyncio.gather()`

### Step 4: Preserve Business Logic ‚úÖ COMPLETE
**No code changes needed!** Business logic remains unchanged:
- ‚úÖ Database functions (Supabase queries)
- ‚úÖ Calendar booking (Google Calendar API)
- ‚úÖ Email sending (Resend/SMTP)
- ‚úÖ Session management (SESSIONS dict)
- ‚úÖ All FastAPI endpoints

**Note:** Transcript saving is ready but commented out (line 2015-2018).
Can be enabled when database schema is confirmed.

### Step 5: Testing ‚è∏ PENDING
- [ ] Local test with ngrok
- [ ] Call and test greeting
- [ ] Test "demo" flow - verify NO interruptions!
- [ ] Test "signup" flow
- [ ] Verify calendar booking works (if using tools)
- [ ] Verify emails send
- [ ] Check logs for any errors

### Step 6: Deploy to Railway ‚è∏ PENDING
- [ ] Add environment variables to Railway:
  ```
  ELEVENLABS_AGENT_ID=agent_7601k2d8gd4rehpt5xsd81q8bj1m
  ELEVENLABS_CONVERSATIONAL_API_KEY=b03d0247...
  USE_ELEVENLABS_CONVERSATIONAL_AI=true
  ```
- [ ] Commit and push code to GitHub
- [ ] Verify Railway deployment success
- [ ] Monitor logs for errors
- [ ] Production test call

### Step 7: Monitor & Optimize ‚è∏ PENDING
- [ ] Check latency vs OpenAI (expect ~75ms for Flash model)
- [ ] Verify voice quality matches preview (George voice)
- [ ] Test under different network conditions
- [ ] Compare costs (likely lower with ElevenLabs direct)
- [ ] Verify no interruptions during "A Plumbing company" test

---

## API Message Format (‚úÖ VERIFIED from GitHub Examples)

### Authentication
```bash
GET https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id={AGENT_ID}
Headers: xi-api-key: {API_KEY}
Response: {"signed_url": "wss://..."}
```

### Client ‚Üí Server (Sending Audio)
```json
{
  "user_audio_chunk": "base64_encoded_ulaw_audio"
}
```

### Client ‚Üí Server (Pong Response to Ping)
```json
{
  "type": "pong",
  "event_id": "event_id_from_ping"
}
```

### Client ‚Üí Server (Optional: Override Agent Config)
```json
{
  "type": "conversation_initiation_client_data",
  "conversation_config_override": {
    "agent": {
      "prompt": {"prompt": "custom prompt"},
      "first_message": "greeting message"
    }
  }
}
```

### Server ‚Üí Client (Audio Response)
```json
{
  "type": "audio",
  "audio_event": {
    "audio_base_64": "base64_audio"
  }
}
```

**Alternative format:**
```json
{
  "type": "audio",
  "audio": {
    "chunk": "base64_audio"
  }
}
```

### Server ‚Üí Client (Conversation Initiated)
```json
{
  "type": "conversation_initiation_metadata"
}
```

### Server ‚Üí Client (User Interrupted Agent)
```json
{
  "type": "interruption"
}
```

### Server ‚Üí Client (Keepalive Ping)
```json
{
  "type": "ping",
  "ping_event": {
    "event_id": "unique_id"
  }
}
```

### Server ‚Üí Client (Transcripts)
```json
{
  "type": "user_transcript",
  "text": "user's spoken text"
}
```
```json
{
  "type": "agent_transcript",
  "text": "agent's response text"
}
```

**‚úÖ VERIFIED from official ElevenLabs-Twilio integration examples**

---

## Rollback Plan (If Something Goes Wrong)

### Instant Rollback:
```bash
# In Railway dashboard, set:
USE_ELEVENLABS_CONVERSATIONAL_AI=false

# System reverts to OpenAI + ElevenLabs TTS
```

### Code Rollback:
```bash
git checkout main
git push origin main
# Railway auto-deploys previous version
```

**Risk:** VERY LOW (feature flag protects us)

---

## Success Metrics

### Must Have:
- ‚úÖ No interruptions when saying "A Plumbing company"
- ‚úÖ Smooth turn-taking throughout conversation
- ‚úÖ All transcripts saved to database
- ‚úÖ Calendar booking works
- ‚úÖ Emails send correctly

### Nice to Have:
- Latency < 1 second for responses
- Voice quality equals preview
- Costs lower than current setup
- No errors in logs

---

## Estimated Timeline (Tomorrow)

| Task | Time | Status |
|------|------|--------|
| Research API | 30 min | Pending |
| Feature flag | 15 min | Pending |
| WebSocket handler | 1-2 hrs | Pending |
| Business logic | 30 min | Pending |
| Testing | 1 hr | Pending |
| Deployment | 30 min | Pending |
| **TOTAL** | **3-4 hrs** | **Pending** |

**Best time to start:** Fresh morning, focused work session

---

## Questions to Answer Tomorrow

1. Does ElevenLabs support function calling / tools?
   - If yes: Can we integrate calendar booking?
   - If no: Handle it ourselves (same as now)

2. What's the exact audio format?
   - Confirm Œº-law support
   - Check sample rate (8000 Hz for Twilio)

3. How are sessions/conversations managed?
   - Session IDs?
   - Conversation timeouts?

4. What events trigger?
   - conversation_start?
   - conversation_end?
   - turn_start / turn_end?

5. How does error recovery work?
   - Reconnection logic?
   - State preservation?

---

## Files to Modify

1. **bolt_realtime.py** - Main application
   - Add feature flag
   - Add ElevenLabs WebSocket handler
   - Route based on flag

2. **.env** - Environment variables
   - Already added! ‚úÖ

3. **requirements.txt** - Dependencies
   - Already has elevenlabs! ‚úÖ

4. **CLAUDE.md** - Documentation
   - Update with ElevenLabs integration details
   - Note the migration

---

## Current Status: READY FOR TOMORROW

### Completed Tonight:
- ‚úÖ ElevenLabs agent configured and tested
- ‚úÖ API credentials obtained
- ‚úÖ Environment variables added
- ‚úÖ Draft implementation skeleton created
- ‚úÖ Comprehensive migration plan documented

### Tomorrow Morning:
1. Review this plan
2. Research exact API format
3. Implement step-by-step
4. Test thoroughly
5. Deploy with confidence

**Expected Result:** No more interruptions, better voice quality, simpler codebase!

---

## Notes & Observations

### What Worked Well in Preview:
- Perfect turn-taking (no interruptions!)
- Natural conversation flow
- George voice sounds great
- GPT-4o understanding is excellent

### Potential Challenges:
- WebSocket protocol differences from OpenAI
- Event handling might be different
- Need to verify transcript extraction works

### Confidence Level: HIGH ‚úÖ
- Preview test was perfect
- Architecture is straightforward
- Most code stays the same
- Feature flag provides safety net

---

**Ready to execute tomorrow with fresh minds and full focus!** üöÄ
